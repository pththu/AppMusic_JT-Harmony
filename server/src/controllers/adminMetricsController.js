const { genAI } = require("../configs/gemini");
const { sequelize, Post, Comment, Like, PostReport, Conversation, Message, User, SearchHistory } = require("../models");
const { Op } = require("sequelize");

const MAX_RETRIES = 3;
const BASE_DELAY_MS = 1000;

// Chuy·ªÉn ƒë·ªïi string th√†nh date
function parseDateStr(s) {
  if (!s) return null;
  // Accept yyyy-MM-dd or MM/DD/YYYY
  if (s.includes('-')) {
    // Expect yyyy-MM-dd
    const d = new Date(`${s}T00:00:00`);
    return isNaN(d.getTime()) ? null : d;
  }
  if (s.includes('/')) {
    const [a, b, yyyy] = s.split('/');
    if (a && b && yyyy) {
      // If first token > 12 assume dd/MM/yyyy, else assume MM/DD/YYYY
      const dd = parseInt(a, 10) > 12 ? a : b;
      const mm = parseInt(a, 10) > 12 ? b : a;
      const iso = `${yyyy}-${String(mm).padStart(2, '0')}-${String(dd).padStart(2, '0')}T00:00:00`;
      const d = new Date(iso);
      return isNaN(d.getTime()) ? null : d;
    }
  }
  const d = new Date(s);
  return isNaN(d.getTime()) ? null : d;
}

// Chuy·ªÉn ƒë·ªïi query th√†nh range
function parseRange(query) {
  const today = new Date();
  let end = parseDateStr(query.dateTo);
  if (!end) {
    end = new Date(Date.UTC(today.getFullYear(), today.getMonth(), today.getDate() + 1));
  } else {
    // Make dateTo inclusive by moving end to the start of the next day
    end = new Date(end.getTime() + 24 * 60 * 60 * 1000);
  }
  let start = parseDateStr(query.dateFrom);
  if (!start) start = new Date(end.getTime() - 7 * 24 * 60 * 60 * 1000);
  // Ensure start <= end
  if (start.getTime() >= end.getTime()) {
    // swap or adjust to 7 days window ending at end
    start = new Date(end.getTime() - 7 * 24 * 60 * 60 * 1000);
  }
  return { start, end };
}

// Chuy·ªÉn ƒë·ªïi granularity th√†nh day, week, month
function parseGranularity(g) {
  const allowed = ["day", "week", "month"];
  return allowed.includes(g) ? g : "day";
}

// T√≠nh t·ªïng s·ªë l∆∞·ª£ng Model trong kho·∫£ng th·ªùi gian
async function countBetween(Model, dateField, start, end) {
  const where = {};
  where[dateField] = { [Op.gte]: start, [Op.lt]: end };
  return await Model.count({ where });
}

// L·∫•y summary
exports.getSummary = async (req, res) => {
  try {
    const { start, end } = parseRange(req.query);
    const [posts, comments, likes, reports, conversations, messages] = await Promise.all([
      countBetween(Post, "uploadedAt", start, end),
      countBetween(Comment, "commentedAt", start, end),
      countBetween(Like, "liked_at", start, end),
      countBetween(PostReport, "reportedAt", start, end),
      countBetween(Conversation, "createdAt", start, end),
      countBetween(Message, "createdAt", start, end),
    ]);

    if (posts === null || comments === null || likes === null || reports === null || conversations === null || messages === null) {
      return res.status(500).json({ error: "Failed to fetch summary counts" });
    }
    return res.status(200).json({ posts, comments, likes, reports, conversations, messages, range: { start, end } });
  } catch (e) {
    console.error("metrics summary error", e);
    return res.status(500).json({ error: "Failed to fetch summary" });
  }
};


const tsMap = {
  posts: { table: 'posts', col: 'uploaded_at' },
  comments: { table: 'comments', col: 'commented_at' },
  likes: { table: 'likes', col: 'liked_at' },
  messages: { table: 'messages', col: 'created_at' },
  conversations: { table: 'conversations', col: 'created_at' },
};

// L·∫•y chu·ªói th·ªùi gian (timeseries) cho 1 lo·∫°i d·ªØ li·ªáu
async function timeseriesRaw(kind, start, end, granularity) {
  const m = tsMap[kind];
  if (!m) throw new Error('invalid kind');
  const gran = ['day', 'week', 'month'].includes(granularity) ? granularity : 'day';
  const sql = `
    SELECT DATE_TRUNC('${gran}', "${m.col}") AS bucket, COUNT(*)::int AS count
    FROM "${m.table}"
    WHERE "${m.col}" >= :start AND "${m.col}" < :end
    GROUP BY bucket
    ORDER BY bucket ASC
  `;
  try {
    const rows = await sequelize.query(sql, {
      type: sequelize.QueryTypes.SELECT,
      replacements: { start, end },
    });
    return rows.map(r => ({ date: r.bucket, count: parseInt(r.count, 10) }));
  } catch (e) {
    console.error(`metrics timeseriesRaw error for kind=${kind}:`, e.message);
    return [];
  }
}

// L·∫•y chu·ªói th·ªùi gian (timeseries) cho 1 lo·∫°i d·ªØ li·ªáu
exports.getTimeseries = async (req, res) => {
  try {
    const kind = (req.params.kind || "posts").toLowerCase();
    const { start, end } = parseRange(req.query);
    const granularity = parseGranularity(req.query.granularity);
    let data;
    if (["posts", "comments", "likes", "messages", "conversations"].includes(kind)) {
      data = await timeseriesRaw(kind, start, end, granularity);
    } else {
      return res.status(400).json({ error: "Invalid timeseries kind" });
    }
    return res.status(200).json({ kind, granularity, data });
  } catch (e) {
    console.error("metrics timeseries error", e);
    return res.status(500).json({ error: "Failed to fetch timeseries" });
  }
};

// L·∫•y s·ªë l∆∞·ª£ng b√°o c√°o theo tr·∫°ng th√°i
exports.getReportsStatusBreakdown = async (req, res) => {
  try {
    const { start, end } = parseRange(req.query);
    const rows = await PostReport.findAll({
      where: { reportedAt: { [Op.gte]: start, [Op.lt]: end } },
      attributes: ["status", [sequelize.fn("COUNT", sequelize.col("id")), "count"]],
      group: ["status"],
      raw: true,
    });
    if (!rows) {
      return res.status(500).json({ error: "Failed to fetch reports breakdown" });
    }
    return res.status(200).json(rows);
  } catch (e) {
    console.error("metrics reports breakdown error", e);
    return res.status(500).json({ error: "Failed to fetch reports breakdown" });
  }
};

// L·∫•y s·ªë l∆∞·ª£ng b√†i ƒëƒÉng theo cover
exports.getPostsCoverBreakdown = async (req, res) => {
  try {
    const { start, end } = parseRange(req.query);
    const rows = await Post.findAll({
      where: { uploadedAt: { [Op.gte]: start, [Op.lt]: end } },
      attributes: ["isCover", [sequelize.fn("COUNT", sequelize.col("id")), "count"]],
      group: ["isCover"],
      raw: true,
    });
    if (!rows) {
      return res.status(500).json({ error: "Failed to fetch posts cover breakdown" });
    }
    return res.status(200).json(rows);
  } catch (e) {
    console.error("metrics posts cover breakdown error", e);
    return res.status(500).json({ error: "Failed to fetch posts cover breakdown" });
  }
};

// L·∫•y top b√†i ƒëƒÉng
exports.getTopPosts = async (req, res) => {
  try {
    const { start, end } = parseRange(req.query);
    const by = (req.query.by || "likes").toLowerCase();
    const limit = parseInt(req.query.limit, 10) || 5;
    const where = { uploadedAt: { [Op.gte]: start, [Op.lt]: end } };
    let order;
    if (by === "likes") order = [["heartCount", "DESC"]];
    else if (by === "comments") order = [["commentCount", "DESC"]];
    else return res.status(400).json({ error: "Invalid 'by' param" });
    const rows = await Post.findAll({ where, order, limit, include: [{ model: User, as: "User", attributes: ["id", "username", "fullName", "avatarUrl"] }] });
    return res.status(200).json(rows);
  } catch (e) {
    console.error("metrics top posts error", e);
    return res.status(500).json({ error: "Failed to fetch top posts" });
  }
};

// L·∫•y top ng∆∞·ªùi d√πng
exports.getTopUsers = async (req, res) => {
  try {
    const { start, end } = parseRange(req.query);
    const by = (req.query.by || "posts").toLowerCase();
    const limit = parseInt(req.query.limit, 10) || 5;
    if (by === "posts") {
      const rows = await Post.findAll({
        where: { uploadedAt: { [Op.gte]: start, [Op.lt]: end } },
        attributes: ["userId", [sequelize.fn("COUNT", sequelize.col("id")), "count"]],
        group: ["userId"],
        order: [[sequelize.literal("count"), "DESC"]],
        limit,
        raw: true,
      });
      const users = await User.findAll({ where: { id: { [Op.in]: rows.map(r => r.userId) } }, attributes: ["id", "username", "fullName", "avatarUrl"], raw: true });
      const data = rows.map(r => ({ ...r, User: users.find(u => u.id === r.userId) }));
      return res.status(200).json(data);
    } else if (by === "comments") {
      const rows = await Comment.findAll({
        where: { commentedAt: { [Op.gte]: start, [Op.lt]: end } },
        attributes: ["userId", [sequelize.fn("COUNT", sequelize.col("id")), "count"]],
        group: ["userId"],
        order: [[sequelize.literal("count"), "DESC"]],
        limit,
        raw: true,
      });
      const users = await User.findAll({ where: { id: { [Op.in]: rows.map(r => r.userId) } }, attributes: ["id", "username", "fullName", "avatarUrl"], raw: true });
      const data = rows.map(r => ({ ...r, User: users.find(u => u.id === r.userId) }));
      return res.status(200).json(data);
    }
    return res.status(400).json({ error: "Invalid 'by' param" });
  } catch (e) {
    console.error("metrics top users error", e);
    return res.status(500).json({ error: "Failed to fetch top users" });
  }
};



/////////////////////////////////////
exports.analyzeBehaviorSearch = async (req, res) => {
  try {
    if (!req.user || !req.user.id) {
      return res.status(401).json({ error: 'Unauthorized' });
    }

    const histories = req.body.histories;

    // const histories = await SearchHistory.findAll({
    //   where: {
    //     searchedAt: { [Op.gte]: new Date(Date.now() - 90 * 24 * 60 * 60 * 1000) } // L·∫•y l·ªãch s·ª≠ trong 90 ng√†y g·∫ßn nh·∫•t
    //   }
    // });
    if (!histories || histories.length === 0) {
      return res.status(200).json({
        message: 'No search history data found for analysis.',
        topKeywords: [],
        trendsOverTime: []
      });
    }

    const z = require("zod"); // Gi·∫£ ƒë·ªãnh th∆∞ vi·ªán zod ƒë√£ ƒë∆∞·ª£c import
    const { zodToJsonSchema } = require("zod-to-json-schema"); // Gi·∫£ ƒë·ªãnh h√†m n√†y ƒë√£ ƒë∆∞·ª£c import

    const keywordSchema = z.object({
      keyword: z.string().describe("T·ª´ kh√≥a ho·∫∑c c·ª•m t·ª´ ph·ªï bi·∫øn"),
      count: z.number().describe("S·ªë l·∫ßn xu·∫•t hi·ªán"),
    });

    const trendSchema = z.object({
      timePeriod: z.string().describe("Kho·∫£ng th·ªùi gian (v√≠ d·ª•: 20:00 - 21:00 - theo gi·ªù)"),
      searchCount: z.number().describe("T·ªïng s·ªë l∆∞·ª£t t√¨m ki·∫øm trong kho·∫£ng th·ªùi gian ƒë√≥"),
    });

    const analysisSchema = z.object({
      topKeywords: z.array(keywordSchema).describe("Danh s√°ch c√°c t·ª´ kh√≥a/c·ª•m t·ª´ ph·ªï bi·∫øn nh·∫•t"),
      trendsOverTime: z.array(trendSchema).describe("Ph√¢n t√≠ch xu h∆∞·ªõng t√¨m ki·∫øm theo th·ªùi gian"),
    });

    const formattedHistories = histories.map((h) => {
      return { query: h.query, searchedAt: h.searchedAt };
    });

    const searchContext = `L·ªãch s·ª≠ t√¨m ki·∫øm c·ªßa ng∆∞·ªùi d√πng: ${JSON.stringify(formattedHistories)}`;
    const prompt = `
      B·∫°n l√† chuy√™n gia ph√¢n t√≠ch v√† t·ªïng h·ª£p h√†nh vi ng∆∞·ªùi d√πng tr√™n n·ªÅn t·∫£ng √¢m nh·∫°c.
      D·ªÆ LI·ªÜU L·ªäCH S·ª¨ T√åM KI·∫æM H·ªÜ TH·ªêNG:
      ${searchContext}

      NHI·ªÜM V·ª§:
      D·ª±a tr√™n t·∫•t c·∫£ l·ªãch s·ª≠ t√¨m ki·∫øm ƒë∆∞·ª£c cung c·∫•p.
      Ph√¢n t√≠ch v√† t√≥m t·∫Øt c√°c xu h∆∞·ªõng t√¨m ki·∫øm ch√≠nh m√† ng∆∞·ªùi d√πng quan t√¢m.
      1. X√°c ƒë·ªãnh c√°c xu h∆∞·ªõng t√¨m ki·∫øm ph·ªï bi·∫øn nh·∫•t (v√≠ d·ª•: T√™n ngh·ªá sƒ©, t√™n b√†i h√°t, th·ªÉ lo·∫°i, ch·ªß ƒë·ªÅ).
      2. Nh·∫≠n di·ªán 10 t·ª´ kh√≥a/c·ª•m t·ª´ ƒë∆∞·ª£c t√¨m ki·∫øm nhi·ªÅu nh·∫•t v√† ƒë·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa ch√∫ng.
      3. Ph√¢n t√≠ch h√†nh vi t√¨m ki·∫øm theo th·ªùi gian (kho·∫£ng t·ª´ m·∫•y gi·ªù ƒë·∫øn m·∫•y gi·ªù) ƒë·ªÉ x√°c ƒë·ªãnh c√°c kho·∫£ng th·ªùi gian cao ƒëi·ªÉm.
      4. Ph√¢n t√≠ch xu h∆∞·ªõng theo th·ªùi gian trong ng√†y
      Y√™u c·∫ßu:
      1. T·ª´ kh√≥a/c·ª•m t·ª´ ph·∫£i ng·∫Øn g·ªçn, r√µ r√†ng (v√≠ d·ª•: "S∆°n T√πng", "Bolero", "Playlist h·ªçc t·∫≠p").
      2. Ph√¢n t√≠ch c·∫ßn ph·∫£n √°nh xu h∆∞·ªõng hi·ªán t·∫°i v√† nh·ªØng thay ƒë·ªïi n·∫øu c√≥.
      3. Ch·ªâ tr·∫£ v·ªÅ 20 t·ª´ kh√≥a/c·ª•m t·ª´ ph·ªï bi·∫øn nh·∫•t.

      üîß FORMAT OUTPUT:
      Tr·∫£ v·ªÅ ƒê√öNG format JSON array sau (kh√¥ng th√™m markdown, kh√¥ng gi·∫£i th√≠ch):
      {
        "topKeywords": [ 
          { "keyword": "string", "count": number }
        ],
        "trendsOverTime": [ 
          { "timePeriod": "string", "searchCount": number }
        ]
      }
      
      Quy t·∫Øc:
      - Tr·∫£ v·ªÅ JSON h·ª£p l·ªá.
      - S·ª≠ d·ª•ng ti·∫øng Vi·ªát trong ph√¢n t√≠ch v√† tr·∫£ v·ªÅ k·∫øt qu·∫£.

      H√£y b·∫Øt ƒë·∫ßu ph√¢n t√≠ch v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON.
    `.trim();


    let response;
    let lastError = null;

    // C∆° ch·∫ø th·ª≠ l·∫°i (Retry Mechanism) t∆∞∆°ng t·ª± nh∆∞ h√†m m·∫´u
    for (let attempt = 0; attempt < MAX_RETRIES; attempt++) {
      try {
        console.log(`üß† G·ªçi Gemini API (L·∫ßn th·ª≠ ${attempt + 1}/${MAX_RETRIES})...`);
        // Gi·∫£ ƒë·ªãnh genAI.models.generateContent ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh v·ªõi th∆∞ vi·ªán @google/genai
        // D√πng API Gemini v·ªõi schema validation
        response = await genAI.models.generateContent({
          model: "gemini-2.5-flash-lite", // S·ª≠ d·ª•ng model ph√π h·ª£p cho ph√¢n t√≠ch
          contents: prompt,
          config: {
            responseMimeType: "application/json",
            responseJsonSchema: zodToJsonSchema(analysisSchema),
          },
          generationConfig: {
            temperature: 0.5, // Nhi·ªát ƒë·ªô th·∫•p h∆°n cho t√°c v·ª• ph√¢n t√≠ch, c·∫ßn ƒë·ªô ch√≠nh x√°c cao
            maxOutputTokens: 2048,
          },
        });

        console.log("‚úÖ API call th√†nh c√¥ng!");
        lastError = null;
        break;
      } catch (error) {
        lastError = error;
        if (error.status === 503) {
          console.warn(`L·∫ßn th·ª≠ ${attempt + 1} th·∫•t b·∫°i (503 Overloaded).`);
          if (attempt < MAX_RETRIES - 1) {
            const delay = BASE_DELAY_MS * (2 ** attempt);
            console.log(`...Ch·ªù ${delay}ms tr∆∞·ªõc khi th·ª≠ l·∫°i...`);
            await new Promise(resolve => setTimeout(resolve, delay));
          }
        } else {
          console.error("L·ªói API kh√¥ng th·ªÉ th·ª≠ l·∫°i:", error.message);
          break;
        }
      }
    }

    if (lastError) {
      console.error("T·∫•t c·∫£ c√°c l·∫ßn th·ª≠ l·∫°i ƒë·ªÅu th·∫•t b·∫°i.");
      return res.status(500).json({
        error: "Kh√¥ng th·ªÉ ph√¢n t√≠ch h√†nh vi t√¨m ki·∫øm sau nhi·ªÅu l·∫ßn th·ª≠ l·∫°i",
        details: lastError.message
      });
    }

    // --- B∆Ø·ªöC 3: X·ª¨ L√ù V√Ä TR·∫¢ V·ªÄ K·∫æT QU·∫¢ ---
    const responseText = response.candidates[0].content.parts[0].text;
    let analysisResult;
    try {
      // Validate v√† parse JSON
      analysisResult = analysisSchema.parse(JSON.parse(responseText));
    } catch (parseError) {
      console.error("‚ùå JSON parse or validation error:", parseError);
      return res.status(500).json({
        success: false,
        error: "Kh√¥ng th·ªÉ parse ho·∫∑c validate k·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ AI",
        rawResponse: responseText
      });
    }

    res.status(200).json({
      message: "Ph√¢n t√≠ch h√†nh vi t√¨m ki·∫øm th√†nh c√¥ng",
      success: true,
      data: analysisResult,
    });
  } catch (error) {
    res.status(500).json({ error: 'Internal server error:  ' + error.message });
  }
}
